model.matrix(spamtype~., spam.train)[,-1]
library(glmnet)
x <- model.matrix(spamtype~., spam.train, family = ‘binomial’)
library(glmnet)
x <- model.matrix(spamtype~., spam.train)
y <- spam.train$spamtype
grid <- 10^seq(5, -5, length=100)
ridge.mod <- cv.glmnet(x,y,alpha=0, lambda=grid, family = ‘binomial’)
library(glmnet)
x <- model.matrix(spamtype~., spam.train)
y <- spam.train$spamtype
grid <- 10^seq(5, -5, length=100)
ridge.mod <- cv.glmnet(x,y,alpha=0, lambda=grid, family = 'binomial')
library(glmnet)
x <- model.matrix(spamtype~., spam.train)
y <- spam.train$spamtype
grid <- 10^seq(5, -5, length=100)
set.seed(1)
cv.out <- cv.glmnet(x,y,alpha=0, lambda=grid, family = 'binomial')
plot(cv.out)
bestlam = cv.out$lambda.min
bestlam
library(glmnet)
x.train <- model.matrix(spamtype~., spam.train)
y.train <- spam.train$spamtype
grid <- 10^seq(5, -5, length=100)
set.seed(1)
cv.out <- cv.glmnet(x.train, y.train, alpha=0, lambda=grid, family = 'binomial')
plot(cv.out)
bestlam = cv.out$lambda.min
bestlam
x.test <- model.matrix(spamtype~., spam.test)
y.test <- spam.test$spamtype
ridge.mod <- glmnet(x,y,alpha=0, lambda=grid, family = 'binomial')
ridge.pred <- predict(ridge.mod, s=bestlam, newx=x.test)
mean((ridge.pred - y.test)^2)
ridge.mod <- glmnet(x.train, y.train, alpha=0, lambda=grid, family = 'binomial')
x.test <- model.matrix(spamtype~., spam.test)
y.test <- spam.test$spamtype
ridge.pred <- predict(ridge.mod, s=bestlam, newx=x.test, type='response')
mean((ridge.pred - y.test)^2)
x.test <- model.matrix(spamtype~., spam.test)
y.test <- spam.test$spamtype
ridge.pred <- predict(ridge.mod, s=bestlam, newx=x.test, type='response')
#mean((ridge.pred - y.test)^2)
x.test <- model.matrix(spamtype~., spam.test)
y.test <- spam.test$spamtype
ridge.pred <- predict(ridge.mod, s=bestlam, newx=x.test, type='response')[,1]
mean((ridge.pred - y.test)^2)
View(x.test)
View(x.test)
View(x.train)
View(x.train)
x.test <- model.matrix(spamtype~., spam.test)
y.test <- spam.test$spamtype
ridge.pred <- predict(ridge.mod, s=bestlam, newx=x.test, type='response')
classification <- ifelse(ridge.pred > 0.5, 'ham', 'spam')
mean(classification == y.test)
x.test <- model.matrix(spamtype~., spam.test)
y.test <- spam.test$spamtype
ridge.pred <- predict(ridge.mod, s=bestlam, newx=x.test, type='response')
classification <- ifelse(ridge.pred > 0.5, 'spam', 'ham')
mean(classification == y.test)
x.test <- model.matrix(spamtype~., spam.test)
y.test <- spam.test$spamtype
ridge.pred <- predict(ridge.mod, s=bestlam, newx=x.test, type='response')
classification <- ifelse(ridge.pred > 0.5, 'spam', 'ham')
mean(classification == y.test)
noreg.mod <- glmnet(x.train, y.train, alpha=0, lambda=0, family = 'binomial')
noreg.pred <- predict(noreg.mod, newx=x.test, type='response')
noreg.classification <- ifelse(noreg.pred > 0.5, 'spam', 'ham')
mean(noreg.classification == y.test)
dim(coef(ridge.mod))
dim(coef(ridge.mod))
ridge.mod$lambda[50]
coef(ridge.mod)[ ,50]
dim(coef(ridge.mod))
ridge.mod$lambda[50]
coef(ridge.mod)[ ,50]
lasso.mod <- glmnet(x.train, y.train, alpha=1, lambda=grid, family = 'binomial')
dim(coef(lasso.mod))
lasso.mod$lambda[50]
coef(lasso.mod)[ ,50]
View(iris)
train.X <- iris[, -1]
View(train.X)
View(train.X)
train.X <- iris[ , -5]
View(train.X)
View(train.X)
train.Y <- iris[ , 5]
library(class)
View(iris)
trainindices <- sample(1:150, 75)
train.df <- iris[trainindices, ]
test.df <- iris[-trainindices, ]
train.X <- train.df[ , -5]
train.Y <- train.df[ , 5]
test.X <- test.df[ , -5]
test.Y <- test.df[ , 5]
knn.pred <- knn(train.X, test.X, train.Y, k=1)
mean(knn.pred==test.Y)
knn.pred1 <- knn(train.X, test.X, train.Y, k=1)
mean(knn.pred==test.Y)
knn.pred1 <- knn(train.X, test.X, train.Y, k=1)
mean(knn.pred1==test.Y)
knn.pred5 <- knn(train.X, test.X, train.Y, k=5)
mean(knn.pred5==test.Y)
titanic.train = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/titanic_train.csv")
titanic.test = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/titanic_test.csv")
View(titanic.test)
View(titanic.test)
View(titanic.train)
View(titanic.train)
library(leaps)
install.packages("titanic")
library(leaps)
select.fit <- regsubsets(Survived ~ Pclass + Sex + Age + SibSp + Parch + Embarked, data = titanic.train)
summary.obj <- summary(select.fit)
summary.obj
select.fit <- regsubsets(Survived ~ Pclass + Sex + Age + SibSp + Parch + Embarked + Parch*Sex + SibSp*Sex, data = titanic.train)
summary.obj <- summary(select.fit)
summary.obj
select.fit <- regsubsets(Survived ~ Pclass + Sex + Age + SibSp + Parch + Embarked*Pclass + Parch*Sex + SibSp*Sex, data = titanic.train)
summary.obj <- summary(select.fit)
summary.obj
select.fit <- regsubsets(Survived ~ Pclass + Sex + Age + SibSp + Parch + Embarked + Embarked*Pclass + Parch*Sex + SibSp*Sex, data = titanic.train)
summary.obj <- summary(select.fit)
summary.obj
fit.model <- glm(Survived ~ Pclass + Sex + Age + SibSp + Parch + Embarked + Embarked*Pclass + Parch*Sex, family= 'binomial', data = titanic.train)
prediction <- predict(fit.model, type = 'response', newx = titanic.test)
classify <- ifelse(prediction > 0.5, 1, 0)
mean(classify == t.test$Survived)
mean(classify == titanic.test$Survived)
fit.model <- glm(Survived ~ Pclass + Sex + Age + SibSp + Parch + Embarked + Embarked*Pclass + Parch*Sex, family= 'binomial', data = titanic.train)
prediction <- predict(fit.model, type = 'response')
classify <- ifelse(prediction > 0.5, 1, 0)
mean(classify == titanic.train$Survived)
length(classify)
length(titanic.train$Survived)
fit.model <- glm(Survived ~ Pclass + Sex + Age + SibSp + Parch + Embarked + Embarked*Pclass + Parch*Sex, family= 'binomial', data = titanic.train)
prediction <- predict(fit.model, type = 'response')
classify <- ifelse(prediction > 0.5, 1, 0)
mean(classify == titanic.train$Survived)
length(classify)
length(titanic.train$Survived)
titanic.train <- na.omit(titanic.train)
library(leaps)
select.fit <- regsubsets(Survived ~ Pclass + Sex + Age + SibSp + Parch + Embarked + Embarked*Pclass + Parch*Sex + SibSp*Sex, data = titanic.train)
summary.obj <- summary(select.fit)
summary.obj
fit.model <- glm(Survived ~ Pclass + Sex + Age + SibSp + Parch + Embarked + Embarked*Pclass + Parch*Sex, family= 'binomial', data = titanic.train)
prediction <- predict(fit.model, type = 'response')
classify <- ifelse(prediction > 0.5, 1, 0)
mean(classify == titanic.train$Survived)
length(classify)
length(titanic.train$Survived)
fit.model <- glm(Survived ~ Pclass + Sex + Age + SibSp + Parch + Parch*Sex, family= 'binomial', data = titanic.train)
prediction <- predict(fit.model, type = 'response')
classify <- ifelse(prediction > 0.5, 1, 0)
mean(classify == titanic.train$Survived)
fit.model <- glm(Survived ~ Pclass + Sex + Age + SibSp + Parch*Sex, family= 'binomial', data = titanic.train)
prediction <- predict(fit.model, type = 'response')
classify <- ifelse(prediction > 0.5, 1, 0)
mean(classify == titanic.train$Survived)
44/ (44+11)
getwd()
knitr::opts_chunk$set(echo = TRUE)
library(leaps)
dat = read.csv("Documents/MSLIS/IS542/Data/popgrowth.csv")
View(dat)
View(dat)
library(leaps)
dat = read.csv("Documents/MSLIS/IS542/Data/popgrowth.csv")
library(leaps)
dat = read.csv("./Documents/MSLIS/IS542/Data/popgrowth.csv")
library(leaps)
dat = read.csv("/Documents/MSLIS/IS542/Data/popgrowth.csv")
library(leaps)
dat = read.csv("Documents/MSLIS/IS542/Data/popgrowth.csv")
getwd()
library(leaps)
dat = read.csv("./Documents/MSLIS/IS542/Data/popgrowth.csv")
library(leaps)
dat = read.csv("./Documents/MSLIS/IS542/Data/popgrowth.csv")
library(leaps)
countygrowth = read.csv("./Documents/MSLIS/IS542/Data/popgrowth.csv")
library(leaps)
countygrowth = read.csv("./Documents/MSLIS/IS542/Data/popgrowth.csv")
library(leaps)
countygrowth = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/popgrowth.csv")
select.fit <- regsubsets(growth ~ ., dat, nvmax = 7)
select.fit
library(leaps)
countygrowth = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/popgrowth.csv")
select.fit <- regsubsets(growth ~ ., dat, nvmax = 7)
summary.fits <- summary(select.fit)
summary.fits
library(leaps)
countygrowth = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/popgrowth.csv")
select.fit <- regsubsets(growth ~ ., dat, nvmax = 7)
summary.fits <- summary(select.fit)
summary.fits
summary.fits$adjr2
coef(select.fit, 6)
library(leaps)
countygrowth = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/popgrowth.csv")
select.fit <- regsubsets(growth ~ ., dat, nvmax = 7)
summary.fits <- summary(select.fit)
summary.fits
summary.fits$adjr2
summary.fits$bic
coef(select.fit, 6)
coef(select.fit, 5)
plot(select.fit, scale = 'bic')
plot(select.fit, scale = 'adjr2')
plot(select.fit, scale = 'adjr2')
plot(select.fit, scale = 'bic')
best.model <- glm(growth ~ .-airquality, data=countygrowth)
summary(best.model)
best.model <- glm(growth ~ .-airquality, data=countygrowth)
summary(best.model)
best.model$residuals^2
best.model <- glm(growth ~ .-airquality, data=countygrowth)
summary(best.model)
mean(best.model$residuals^2)
library(boot)
set.seed(1)
cv.out <- cv.glm(countygrowth, best.model, K=10)
cv.out$delta
reviews.train = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_train.tsv", sep="\t")
reviews.test = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_test.tsv", sep="\t")
View(reviews.train)
View(reviews.train)
reviews.train = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_train.tsv", sep="\t")
reviews.test = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_test.tsv", sep="\t")
X = model.matrix(sentiment ~ ., reviews.train)[, -1] # takes off salary
y = reviews.train$sentiment
View(X)
View(X)
reviews.train = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_train.tsv", sep="\t")
reviews.test = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_test.tsv", sep="\t")
X.train = model.matrix(sentiment ~ ., reviews.train)[, -1] # takes off sentiment
y.train = reviews.train$sentiment
grid = 10^seq(10,-2,length=100)
set.seed(1)
cv.out = cv.glmnet(X.train, y.train, alpha=0, lambda = grid)
library(glmnet)
reviews.train = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_train.tsv", sep="\t")
reviews.test = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_test.tsv", sep="\t")
X.train = model.matrix(sentiment ~ ., reviews.train)[, -1] # takes off sentiment
y.train = reviews.train$sentiment
grid = 10^seq(10,-2,length=100)
set.seed(1)
cv.out = cv.glmnet(X.train, y.train, alpha=0, lambda = grid)
plot(cv.out)
bestlam=cv.out$lambda.min
bestlam
library(glmnet)
reviews.train = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_train.tsv", sep="\t")
reviews.test = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_test.tsv", sep="\t")
X.train = model.matrix(sentiment ~ ., reviews.train)[, -1] # takes off sentiment
y.train = reviews.train$sentiment
grid <- 10^seq(5, -5, length=100)
set.seed(1)
cv.out = cv.glmnet(X.train, y.train, alpha=0, lambda = grid)
plot(cv.out)
bestlam=cv.out$lambda.min
bestlam
library(glmnet)
reviews.train = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_train.tsv", sep="\t")
reviews.test = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_test.tsv", sep="\t")
X.train = model.matrix(sentiment ~ ., reviews.train)[, -1] # takes off sentiment
y.train = reviews.train$sentiment
grid <- 10^seq(5, -5, length=100)
set.seed(1)
cv.out = cv.glmnet(X.train, y.train, alpha=0, lambda = grid, family = 'binomial')
plot(cv.out)
bestlam=cv.out$lambda.min
bestlam
bestlam=cv.out$lambda.min
bestlam
library(glmnet)
reviews.train = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_train.tsv", sep="\t")
reviews.test = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_test.tsv", sep="\t")
X.train = model.matrix(sentiment ~ ., reviews.train)[, -1] # takes off sentiment
y.train = reviews.train$sentiment
grid <- 10^seq(1, -1, length=100)
set.seed(1)
cv.out = cv.glmnet(X.train, y.train, alpha=0, lambda = grid, family = 'binomial')
plot(cv.out)
bestlam=cv.out$lambda.min
bestlam
library(glmnet)
reviews.train = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_train.tsv", sep="\t")
reviews.test = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_test.tsv", sep="\t")
X.train = model.matrix(sentiment ~ ., reviews.train)[, -1] # takes off sentiment
y.train = reviews.train$sentiment
grid <- 10^seq(10, -10, length=100)
set.seed(1)
cv.out = cv.glmnet(X.train, y.train, alpha=0, lambda = grid, family = 'binomial')
plot(cv.out)
library(glmnet)
reviews.train = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_train.tsv", sep="\t")
reviews.test = read.csv("/Users/jenna/Documents/MSLIS/IS542/Data/reviews_test.tsv", sep="\t")
X.train = model.matrix(sentiment ~ ., reviews.train)[, -1] # takes off sentiment
y.train = reviews.train$sentiment
grid <- 10^seq(2, -2, length=100)
set.seed(1)
cv.out = cv.glmnet(X.train, y.train, alpha=0, lambda = grid, family = 'binomial')
plot(cv.out)
bestlam=cv.out$lambda.min
bestlam
best.model = glmnet(X.train, y.train, alpha = 0, lambda = bestlam, family = 'binomial')
sorted.coefs <- sort(coef(best.model)[, 1], decreasing=True)
best.model = glmnet(X.train, y.train, alpha = 0, lambda = bestlam, family = 'binomial')
sorted.coefs <- sort(coef(best.model)[, 1], decreasing=TRUE)
sorted.coefs[1:5]
best.model = glmnet(X.train, y.train, alpha = 0, lambda = bestlam, family = 'binomial')
sorted.coefs <- sort(coef(best.model)[, 1])
sorted.coefs[1:5]
X.test = model.matrix(sentiment ~ ., reviews.test)[, -1] # takes off sentiment
y.test = reviews.test$sentiment
predictions <- predict(best.model, type = 'response', newx = X.test)
classifications <- ifelse(predictions > 0.5, 1, 0)
mean(classifications == y.test)
confusion.matrix <- table(y.test, classifications)
confusion.matrix
TN <- confusion.matrix[1,1]
TP <- confusion.matrix[2,2]
FN <- confusion.matrix[2,1]
FP <- confusion.matrix[1,2]
accuracy <- (TN + TP) / (TN + TP + FN + FP)
precision <- (TP) / (TP + FP)
recall <- (TP) / (TP + FN)
f1 <- 2 * ( (precision*recall) / (precision + recall) )
install.packages("tinytex")
install.packages("countrycode")
library(countrycode)
?`countrycode-package`
?`countrycode`
?codelist
getwd()
setwd("./Documents/GitHub/international-relations-database-extended/")
setwd("./Documents/GitHub/international-relations-database-extended/Mashup_Data")
setwd("./Documents/GitHub/international-relations-database-extended/Mashup_Data/")
setwd("~/Documents/GitHub/international-relations-database-extended/Mashup_Data/")
getwd()
cow = read.csv("../Data/CoW/cow_states_post1946.csv")
gw = read.csv("../Data/Other/gw_states_post1946.csv")
pol = read.csv("../Data/PolityIV/polity_trimmed.csv")
wb = read.csv("../Data/WorldBank/wb_countries.csv")
# destination = 'iso3c'
cowtoiso <- countrycode(cow$cow_id, origin = 'cown', destination = 'iso3c')
cowtoiso
type(cowtoiso)
typeof(cowtoiso)
cow.df <- data.frame(cowtoiso, cowtoisoname, cow$cow_id, cow$cow_name)
# destination = 'iso3c'
cowtoiso <- countrycode(cow$cow_id, origin = 'cown', destination = 'iso3c')
cowtoisoname <- countrycode(cow$cow_id, origin = 'cown', destination = 'iso.name.en')
cow.df <- data.frame(cowtoiso, cowtoisoname, cow$cow_id, cow$cow_name)
View(cow.df)
View(cow.df)
# GW
gw.to.iso <- countrycode(gw$gw_id, origin = 'gwn', destination = 'iso3c')
gw.to.isoname <- countrycode(gw$gw_id, origin = 'gwn', destination = 'iso.name.en')
gw.df <- data.frame(gw.to.iso, gw.to.isoname, gw$gw_id, gw$gw_name)
View(gw.df)
View(gw.df)
# Polity
pol.ids <- unique(pol$ccode)
pol.to.iso <- countrycode(pol.ids, origin = 'p4n', destination = 'iso3c')
pol.to.isoname <- countrycode(pol.ids, origin = 'p4n', destination = 'iso.name.en')
pol.df <- data.frame(pol.ids, pol.to.iso, pol.to.isoname)
# Polity
pol.ids <- unique(pol$scode)
pol.to.iso <- countrycode(pol.ids, origin = 'p4c', destination = 'iso3c')
pol.to.isoname <- countrycode(pol.ids, origin = 'p4c', destination = 'iso.name.en')
pol.df <- data.frame(pol.ids, pol.to.iso, pol.to.isoname)
View(pol.df)
View(pol.df)
pol = read.csv("../Data/PolityIV/polity_country_list.csv") # origin = 'p4n'
# Polity
pol.to.iso <- countrycode(pol$scode, origin = 'p4c', destination = 'iso3c')
pol.to.isoname <- countrycode(pol$scode, origin = 'p4c', destination = 'iso.name.en')
pol.df <- data.frame(pol$scode, pol$ccode, pol$country, pol.to.iso, pol.to.isoname)
View(pol.df)
View(pol.df)
# Polity
pol.to.iso <- countrycode(pol$ccode, origin = 'p4n', destination = 'iso3c')
# Polity
pol.to.iso <- countrycode(pol$scode, origin = 'p4c', destination = 'iso3c')
pol.to.isoname <- countrycode(pol$scode, origin = 'p4c', destination = 'iso.name.en')
pol.df <- data.frame(pol$scode, pol$ccode, pol$country, pol.to.iso, pol.to.isoname)
# WB
wb.to.iso <- countrycode(wb$id, origin = 'wb', destination = 'iso3c')
wb.to.isoname <- countrycode(wb$id, origin = 'wb', destination = 'iso.name.en')
wb.df <- data.frame(wb.to.iso, wb.to.isoname, wb$id, wb$name)
View(wb.df)
View(wb.df)
codelist_panel
View(codelist_panel)
View(cow.df)
View(cow.df)
# Country Year Panel
needed.columns = c('country.name.en', 'year', 'continent', 'region', 'cowc', 'cown', 'gwc', 'gwn', 'iso3c', 'p4c', 'p4n', 'wb')
country.conversion.table <- subset(codelist_panel, year > 1945, select=needed.columns)
View(country.conversion.table)
View(country.conversion.table)
write.csv(country.conversion.table, '../Data/Other/country_conversion_table.csv')
# Country Year Panel
needed.columns = c('country.name.en', 'year', 'continent', 'region', 'cown', 'gwn', 'iso3c', 'p4n', 'wb')
country.conversion.table <- subset(codelist_panel, year > 1945, select=needed.columns)
write.csv(country.conversion.table, '../Data/Other/country_conversion_table.csv')
gw_micro <- read.table("../Data/Other/microstatesystem.dat", sep="\t")
gw_micro <- read.table("../Data/Other/microstatessystem.dat", sep="\t")
View(gw_micro)
View(gw_micro)
gw_micro <- read.table("../Data/Other/microstatessystem.dat", sep="\t", fileEncoding = 'utf-8')
View(gw_micro)
View(gw_micro)
gw_micro <- read.table("../Data/Other/microstatessystem.dat", sep="\t", fileEncoding = 'latin1')
View(gw_micro)
View(gw_micro)
gw_micro <- read.table("../Data/Other/microstatessystem.dat", sep="\t", fileEncoding = 'latin1', col.names = c('gwn', 'gwc', 'gw.name', 'start', 'end'))
View(country.conversion.table)
View(country.conversion.table)
gw_micro <- read.table("../Data/Other/microstatessystem.dat", sep="\t", fileEncoding = 'latin1', col.names = c('gwn', 'gwc', 'gw.name', 'start', 'end'))
gw_micro$gw.name[3]="St. Lucia"
gw_micro$gw.name[4]="St. Vincent & Grenadines"
gw_micro$gw.name[6]="St. Kitts & Nevis"
gw_micro$gw.name[22]="Micronesia (Federated States of)"
gw_micro$gw.name[23]="Samoa"
gw_micro <- gw_micro[-c(11, 12, 13, ), ]
gw_micro <- gw_micro[c('gwn', 'gw.name')]
gw_micro <- read.table("../Data/Other/microstatessystem.dat", sep="\t", fileEncoding = 'latin1', col.names = c('gwn', 'gwc', 'gw.name', 'start', 'end'))
gw_micro$gw.name[3]="St. Lucia"
gw_micro$gw.name[3]=="St. Lucia"
gw_micro <- read.table("../Data/Other/microstatessystem.dat", sep="\t", fileEncoding = 'latin1', col.names = c('gwn', 'gwc', 'gw.name', 'start', 'end'), colClasses=c("character"))
gw_micro$gw.name[3]="St. Lucia"
gw_micro$gw.name[4]="St. Vincent & Grenadines"
gw_micro$gw.name[6]="St. Kitts & Nevis"
gw_micro$gw.name[22]="Micronesia (Federated States of)"
gw_micro$gw.name[23]="Samoa"
gw_micro <- gw_micro[-c(11, 12, 13, ), ]
gw_micro <- gw_micro[c('gwn', 'gw.name')]
gw_micro <- gw_micro[-c(11, 12, 13), ]
country.conversion.table <- merge(country.conversion.table, gw_micro, by.x = 'country.name.en', by.y = 'gw.name')
# Country Year Panel
needed.columns = c('country.name.en', 'year', 'continent', 'region', 'cown', 'gwn', 'iso3c', 'p4n', 'wb')
country.conversion.table <- subset(codelist_panel, year > 1945, select=needed.columns)
gw_micro <- read.table("../Data/Other/microstatessystem.dat", sep="\t", fileEncoding = 'latin1', col.names = c('gw.id', 'gwc', 'gw.name', 'start', 'end'), colClasses=c("character"))
gw_micro$gw.name[3]="St. Lucia"
gw_micro$gw.name[4]="St. Vincent & Grenadines"
gw_micro$gw.name[6]="St. Kitts & Nevis"
gw_micro$gw.name[22]="Micronesia (Federated States of)"
gw_micro$gw.name[23]="Samoa"
gw_micro <- gw_micro[-c(11, 12, 13), ]
gw_micro <- gw_micro[c('gwn', 'gw.name')]
country.conversion.table <- merge(country.conversion.table, gw_micro, by.x = 'country.name.en', by.y = 'gw.name')
# Country Year Panel
needed.columns = c('country.name.en', 'year', 'continent', 'region', 'cown', 'gwn', 'iso3c', 'p4n', 'wb')
country.conversion.table <- subset(codelist_panel, year > 1945, select=needed.columns)
gw_micro <- read.table("../Data/Other/microstatessystem.dat", sep="\t", fileEncoding = 'latin1', col.names = c('gw.id', 'gwc', 'gw.name', 'start', 'end'), colClasses=c("character"))
gw_micro$gw.name[3]="St. Lucia"
gw_micro$gw.name[4]="St. Vincent & Grenadines"
gw_micro$gw.name[6]="St. Kitts & Nevis"
gw_micro$gw.name[22]="Micronesia (Federated States of)"
gw_micro$gw.name[23]="Samoa"
gw_micro <- gw_micro[-c(11, 12, 13), ]
gw_micro <- gw_micro[c('gw.id', 'gw.name')]
country.conversion.table <- merge(country.conversion.table, gw_micro, by.x = 'country.name.en', by.y = 'gw.name')
country.conversion.table$gwn <- ifelse(is.na(country.conversion.table$gwn), country.conversion.table$gw.id, country.conversion.table$gwn)
# Country Year Panel
needed.columns = c('country.name.en', 'year', 'continent', 'region', 'cown', 'gwn', 'iso3c', 'p4n', 'wb')
country.conversion.table <- subset(codelist_panel, year > 1945, select=needed.columns)
gw_micro <- read.table("../Data/Other/microstatessystem.dat", sep="\t", fileEncoding = 'latin1', col.names = c('gw.id', 'gwc', 'gw.name', 'start', 'end'), colClasses=c("character"))
gw_micro$gw.name[3]="St. Lucia"
gw_micro$gw.name[4]="St. Vincent & Grenadines"
gw_micro$gw.name[6]="St. Kitts & Nevis"
gw_micro$gw.name[22]="Micronesia (Federated States of)"
gw_micro$gw.name[23]="Samoa"
gw_micro <- gw_micro[-c(11, 12, 13), ]
gw_micro <- gw_micro[c('gw.id', 'gw.name')]
country.conversion.table <- merge(country.conversion.table, gw_micro, by.x = 'country.name.en', by.y = 'gw.name', all.x=TRUE)
country.conversion.table$gwn <- ifelse(is.na(country.conversion.table$gwn), country.conversion.table$gw.id, country.conversion.table$gwn)
country.conversion.table <- country.conversion.table[-c('gw.id')]
country.conversion.table <- country.conversion.table[-c(-1)]
# Country Year Panel
needed.columns = c('country.name.en', 'year', 'continent', 'region', 'cown', 'gwn', 'iso3c', 'p4n', 'wb')
country.conversion.table <- subset(codelist_panel, year > 1945, select=needed.columns)
gw_micro <- read.table("../Data/Other/microstatessystem.dat", sep="\t", fileEncoding = 'latin1', col.names = c('gw.id', 'gwc', 'gw.name', 'start', 'end'), colClasses=c("character"))
gw_micro$gw.name[3]="St. Lucia"
gw_micro$gw.name[4]="St. Vincent & Grenadines"
gw_micro$gw.name[6]="St. Kitts & Nevis"
gw_micro$gw.name[22]="Micronesia (Federated States of)"
gw_micro$gw.name[23]="Samoa"
gw_micro <- gw_micro[-c(11, 12, 13), ]
gw_micro <- gw_micro[c('gw.id', 'gw.name')]
country.conversion.table <- merge(country.conversion.table, gw_micro, by.x = 'country.name.en', by.y = 'gw.name', all.x=TRUE)
country.conversion.table$gwn <- ifelse(is.na(country.conversion.table$gwn), country.conversion.table$gw.id, country.conversion.table$gwn)
country.conversion.table <- country.conversion.table[-c(1:-1)]
country.conversion.table <- country.conversion.table[-c(1:-2)]
country.conversion.table <- subset(country.conversion.table, select = -c(gw.id))
# drop rows that don't have either CoW codes or G&W codes
country.conversion.table[!with(country.conversion.table, is.na(cown)& is.na(gwn)),]
# drop rows that don't have either CoW codes or G&W codes
country.conversion.table <- country.conversion.table[!with(country.conversion.table, is.na(cown)& is.na(gwn)),]
write.csv(country.conversion.table, '../Data/Other/country_conversion_table.csv')
write.csv(country.conversion.table, '../Data/Other/country_conversion_table.csv', na="", row.names=FALSE)
View(codelist_panel)
